{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and preprocessing the data for NLP analysis\n",
    "Dataset: Tweets_2020_11-March-7-June_workfromhome_all.csv => 29153 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import re\n",
    "import contractions\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os\n",
    "from sentistrength import PySentiStr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import the raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29147, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Web_Page_URL</th>\n",
       "      <th>Tweet_Website</th>\n",
       "      <th>Author_Name</th>\n",
       "      <th>Author_Web_Page_URL</th>\n",
       "      <th>Tweet_Timestamp</th>\n",
       "      <th>Tweet_Time</th>\n",
       "      <th>Tweet_Content</th>\n",
       "      <th>Tweet_Image_URL</th>\n",
       "      <th>Tweet_Number_of_Likes</th>\n",
       "      <th>Tweet_Number_of_Retweets</th>\n",
       "      <th>Tweet_Number_of_Reviews</th>\n",
       "      <th>Retweet_or_not</th>\n",
       "      <th>Retweet_Original_Tweet_Content</th>\n",
       "      <th>Retweet_Original_Tweet_Poster</th>\n",
       "      <th>Retweet_Original_Tweet_Time</th>\n",
       "      <th>Retweet_Original_Tweet_PosterID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Post</td>\n",
       "      <td>(#workfromhome) lang:en until:2020-03-12 since...</td>\n",
       "      <td>https://twitter.com/search?q=(%23workfromhome)...</td>\n",
       "      <td>https://twitter.com/TheWritingFitz/status/1237...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/TheWritingFitz</td>\n",
       "      <td>1.580000e+12</td>\n",
       "      <td>11-03-20 00:14</td>\n",
       "      <td>@CWAUnion\\n Is the union able to take measures...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Post</td>\n",
       "      <td>(#workfromhome) lang:en until:2020-03-12 since...</td>\n",
       "      <td>https://twitter.com/search?q=(%23workfromhome)...</td>\n",
       "      <td>https://twitter.com/digitalkg/status/123753446...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/digitalkg</td>\n",
       "      <td>1.580000e+12</td>\n",
       "      <td>11-03-20 00:23</td>\n",
       "      <td>I’m looking forward to working from home a lot...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Post</td>\n",
       "      <td>(#workfromhome) lang:en until:2020-03-12 since...</td>\n",
       "      <td>https://twitter.com/search?q=(%23workfromhome)...</td>\n",
       "      <td>https://twitter.com/LukeZhang5/status/12375345...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/LukeZhang5</td>\n",
       "      <td>1.580000e+12</td>\n",
       "      <td>11-03-20 00:23</td>\n",
       "      <td>China team work from home more than 1 month al...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Post</td>\n",
       "      <td>(#workfromhome) lang:en until:2020-03-12 since...</td>\n",
       "      <td>https://twitter.com/search?q=(%23workfromhome)...</td>\n",
       "      <td>https://twitter.com/Adamhill1212/status/123753...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/Adamhill1212</td>\n",
       "      <td>1.580000e+12</td>\n",
       "      <td>11-03-20 00:39</td>\n",
       "      <td>We are about to find out how much work could h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>363</td>\n",
       "      <td>28</td>\n",
       "      <td>14.0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Post</td>\n",
       "      <td>(#workfromhome) lang:en until:2020-03-12 since...</td>\n",
       "      <td>https://twitter.com/search?q=(%23workfromhome)...</td>\n",
       "      <td>https://twitter.com/kennethdashen/status/12375...</td>\n",
       "      <td>@kennethdashen</td>\n",
       "      <td>https://twitter.com/kennethdashen</td>\n",
       "      <td>1.580000e+12</td>\n",
       "      <td>11-03-20 00:45</td>\n",
       "      <td>Folks who can't #WorkFromHome probably hate th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Keyword  \\\n",
       "0     Post  (#workfromhome) lang:en until:2020-03-12 since...   \n",
       "1     Post  (#workfromhome) lang:en until:2020-03-12 since...   \n",
       "2     Post  (#workfromhome) lang:en until:2020-03-12 since...   \n",
       "3     Post  (#workfromhome) lang:en until:2020-03-12 since...   \n",
       "4     Post  (#workfromhome) lang:en until:2020-03-12 since...   \n",
       "\n",
       "                                        Web_Page_URL  \\\n",
       "0  https://twitter.com/search?q=(%23workfromhome)...   \n",
       "1  https://twitter.com/search?q=(%23workfromhome)...   \n",
       "2  https://twitter.com/search?q=(%23workfromhome)...   \n",
       "3  https://twitter.com/search?q=(%23workfromhome)...   \n",
       "4  https://twitter.com/search?q=(%23workfromhome)...   \n",
       "\n",
       "                                       Tweet_Website     Author_Name  \\\n",
       "0  https://twitter.com/TheWritingFitz/status/1237...             NaN   \n",
       "1  https://twitter.com/digitalkg/status/123753446...             NaN   \n",
       "2  https://twitter.com/LukeZhang5/status/12375345...             NaN   \n",
       "3  https://twitter.com/Adamhill1212/status/123753...             NaN   \n",
       "4  https://twitter.com/kennethdashen/status/12375...  @kennethdashen   \n",
       "\n",
       "                  Author_Web_Page_URL  Tweet_Timestamp      Tweet_Time  \\\n",
       "0  https://twitter.com/TheWritingFitz     1.580000e+12  11-03-20 00:14   \n",
       "1       https://twitter.com/digitalkg     1.580000e+12  11-03-20 00:23   \n",
       "2      https://twitter.com/LukeZhang5     1.580000e+12  11-03-20 00:23   \n",
       "3    https://twitter.com/Adamhill1212     1.580000e+12  11-03-20 00:39   \n",
       "4   https://twitter.com/kennethdashen     1.580000e+12  11-03-20 00:45   \n",
       "\n",
       "                                       Tweet_Content Tweet_Image_URL  \\\n",
       "0  @CWAUnion\\n Is the union able to take measures...             NaN   \n",
       "1  I’m looking forward to working from home a lot...             NaN   \n",
       "2  China team work from home more than 1 month al...             NaN   \n",
       "3  We are about to find out how much work could h...             NaN   \n",
       "4  Folks who can't #WorkFromHome probably hate th...             NaN   \n",
       "\n",
       "  Tweet_Number_of_Likes Tweet_Number_of_Retweets  Tweet_Number_of_Reviews  \\\n",
       "0                   NaN                      NaN                      NaN   \n",
       "1                   NaN                      NaN                      NaN   \n",
       "2                   NaN                      NaN                      NaN   \n",
       "3                   363                       28                     14.0   \n",
       "4                     1                      NaN                      NaN   \n",
       "\n",
       "  Retweet_or_not  Retweet_Original_Tweet_Content  \\\n",
       "0             No                             NaN   \n",
       "1             No                             NaN   \n",
       "2             No                             NaN   \n",
       "3             No                             NaN   \n",
       "4             No                             NaN   \n",
       "\n",
       "   Retweet_Original_Tweet_Poster  Retweet_Original_Tweet_Time  \\\n",
       "0                            NaN                          NaN   \n",
       "1                            NaN                          NaN   \n",
       "2                            NaN                          NaN   \n",
       "3                            NaN                          NaN   \n",
       "4                            NaN                          NaN   \n",
       "\n",
       "   Retweet_Original_Tweet_PosterID  \n",
       "0                              NaN  \n",
       "1                              NaN  \n",
       "2                              NaN  \n",
       "3                              NaN  \n",
       "4                              NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset = pd.read_csv('Tweets_2020_11-March-7-June_workfromhome_all.csv')\n",
    "print(raw_dataset.shape)\n",
    "raw_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the Author_Name column\n",
    "\n",
    "raw_dataset['Author_Name'] = raw_dataset['Author_Web_Page_URL'].apply(lambda x: '@' + re.findall(r'https://twitter.com/(\\w+)', x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category                               2\n",
       "Keyword                               98\n",
       "Web_Page_URL                         187\n",
       "Tweet_Website                      29073\n",
       "Author_Name                        24126\n",
       "Author_Web_Page_URL                24126\n",
       "Tweet_Timestamp                        2\n",
       "Tweet_Time                         23004\n",
       "Tweet_Content                      29147\n",
       "Tweet_Image_URL                      248\n",
       "Tweet_Number_of_Likes                439\n",
       "Tweet_Number_of_Retweets             181\n",
       "Tweet_Number_of_Reviews              105\n",
       "Retweet_or_not                         1\n",
       "Retweet_Original_Tweet_Content         0\n",
       "Retweet_Original_Tweet_Poster          0\n",
       "Retweet_Original_Tweet_Time            0\n",
       "Retweet_Original_Tweet_PosterID        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many unique values are in each column of the dataset\n",
    "raw_dataset.nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many NaN values are in each column of the dataset and their percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values percentage: \n",
      "\n",
      "Category                             0  0.0000%\n",
      "Keyword                              0  0.0000%\n",
      "Web_Page_URL                         0  0.0000%\n",
      "Tweet_Website                        0  0.0000%\n",
      "Author_Name                          0  0.0000%\n",
      "Author_Web_Page_URL                  0  0.0000%\n",
      "Tweet_Timestamp                      0  0.0000%\n",
      "Tweet_Time                           0  0.0000%\n",
      "Tweet_Content                        0  0.0000%\n",
      "Tweet_Image_URL                  28882  99.0908%\n",
      "Tweet_Number_of_Likes            10222  35.0705%\n",
      "Tweet_Number_of_Retweets         20278  69.5715%\n",
      "Tweet_Number_of_Reviews          18689  64.1198%\n",
      "Retweet_or_not                       0  0.0000%\n",
      "Retweet_Original_Tweet_Content   29147  100.0000%\n",
      "Retweet_Original_Tweet_Poster    29147  100.0000%\n",
      "Retweet_Original_Tweet_Time      29147  100.0000%\n",
      "Retweet_Original_Tweet_PosterID  29147  100.0000%\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values percentage: \\n\")\n",
    "\n",
    "# Calculate the maximum length of the column names\n",
    "coloane = raw_dataset.columns.to_list()\n",
    "max_col_len = max([len(str(col)) for col in coloane])\n",
    "\n",
    "# Define the formatting string with a dynamic width for the column name field\n",
    "fmt_str = '{:<{}}  {:>5}  {:.4f}%'\n",
    "\n",
    "# Iterate over the columns and print the missing values percentage for each one\n",
    "for c in coloane:\n",
    "    if c != 'tconst':\n",
    "        num_missing = len(raw_dataset[raw_dataset[c].isna()])\n",
    "        percent_missing = num_missing / len(raw_dataset) * 100\n",
    "        print(fmt_str.format(c, max_col_len, num_missing, percent_missing))\n",
    "    else:\n",
    "        num_missing = len(raw_dataset[raw_dataset[c].isna()])\n",
    "        percent_missing = num_missing / len(raw_dataset) * 100\n",
    "        print(fmt_str.format(c, max_col_len + 8, num_missing, percent_missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the unnecessary columns from the dataset\n",
    "raw_dataset.drop(['Category','Tweet_Timestamp','Tweet_Image_URL','Retweet_or_not','Retweet_Original_Tweet_Content', 'Retweet_Original_Tweet_Poster', 'Retweet_Original_Tweet_Time', 'Retweet_Original_Tweet_PosterID'], \n",
    "                     axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Web_Page_URL</th>\n",
       "      <th>Tweet_Website</th>\n",
       "      <th>Author_Name</th>\n",
       "      <th>Author_Web_Page_URL</th>\n",
       "      <th>Tweet_Time</th>\n",
       "      <th>Tweet_Content</th>\n",
       "      <th>Tweet_Number_of_Likes</th>\n",
       "      <th>Tweet_Number_of_Retweets</th>\n",
       "      <th>Tweet_Number_of_Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(#workfromhome) lang:en until:2020-03-12 since...</td>\n",
       "      <td>https://twitter.com/search?q=(%23workfromhome)...</td>\n",
       "      <td>https://twitter.com/TheWritingFitz/status/1237...</td>\n",
       "      <td>@TheWritingFitz</td>\n",
       "      <td>https://twitter.com/TheWritingFitz</td>\n",
       "      <td>11-03-20 00:14</td>\n",
       "      <td>@CWAUnion\\n Is the union able to take measures...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(#workfromhome) lang:en until:2020-03-12 since...</td>\n",
       "      <td>https://twitter.com/search?q=(%23workfromhome)...</td>\n",
       "      <td>https://twitter.com/digitalkg/status/123753446...</td>\n",
       "      <td>@digitalkg</td>\n",
       "      <td>https://twitter.com/digitalkg</td>\n",
       "      <td>11-03-20 00:23</td>\n",
       "      <td>I’m looking forward to working from home a lot...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(#workfromhome) lang:en until:2020-03-12 since...</td>\n",
       "      <td>https://twitter.com/search?q=(%23workfromhome)...</td>\n",
       "      <td>https://twitter.com/LukeZhang5/status/12375345...</td>\n",
       "      <td>@LukeZhang5</td>\n",
       "      <td>https://twitter.com/LukeZhang5</td>\n",
       "      <td>11-03-20 00:23</td>\n",
       "      <td>China team work from home more than 1 month al...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(#workfromhome) lang:en until:2020-03-12 since...</td>\n",
       "      <td>https://twitter.com/search?q=(%23workfromhome)...</td>\n",
       "      <td>https://twitter.com/Adamhill1212/status/123753...</td>\n",
       "      <td>@Adamhill1212</td>\n",
       "      <td>https://twitter.com/Adamhill1212</td>\n",
       "      <td>11-03-20 00:39</td>\n",
       "      <td>We are about to find out how much work could h...</td>\n",
       "      <td>363</td>\n",
       "      <td>28</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(#workfromhome) lang:en until:2020-03-12 since...</td>\n",
       "      <td>https://twitter.com/search?q=(%23workfromhome)...</td>\n",
       "      <td>https://twitter.com/kennethdashen/status/12375...</td>\n",
       "      <td>@kennethdashen</td>\n",
       "      <td>https://twitter.com/kennethdashen</td>\n",
       "      <td>11-03-20 00:45</td>\n",
       "      <td>Folks who can't #WorkFromHome probably hate th...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Keyword  \\\n",
       "0  (#workfromhome) lang:en until:2020-03-12 since...   \n",
       "1  (#workfromhome) lang:en until:2020-03-12 since...   \n",
       "2  (#workfromhome) lang:en until:2020-03-12 since...   \n",
       "3  (#workfromhome) lang:en until:2020-03-12 since...   \n",
       "4  (#workfromhome) lang:en until:2020-03-12 since...   \n",
       "\n",
       "                                        Web_Page_URL  \\\n",
       "0  https://twitter.com/search?q=(%23workfromhome)...   \n",
       "1  https://twitter.com/search?q=(%23workfromhome)...   \n",
       "2  https://twitter.com/search?q=(%23workfromhome)...   \n",
       "3  https://twitter.com/search?q=(%23workfromhome)...   \n",
       "4  https://twitter.com/search?q=(%23workfromhome)...   \n",
       "\n",
       "                                       Tweet_Website      Author_Name  \\\n",
       "0  https://twitter.com/TheWritingFitz/status/1237...  @TheWritingFitz   \n",
       "1  https://twitter.com/digitalkg/status/123753446...       @digitalkg   \n",
       "2  https://twitter.com/LukeZhang5/status/12375345...      @LukeZhang5   \n",
       "3  https://twitter.com/Adamhill1212/status/123753...    @Adamhill1212   \n",
       "4  https://twitter.com/kennethdashen/status/12375...   @kennethdashen   \n",
       "\n",
       "                  Author_Web_Page_URL      Tweet_Time  \\\n",
       "0  https://twitter.com/TheWritingFitz  11-03-20 00:14   \n",
       "1       https://twitter.com/digitalkg  11-03-20 00:23   \n",
       "2      https://twitter.com/LukeZhang5  11-03-20 00:23   \n",
       "3    https://twitter.com/Adamhill1212  11-03-20 00:39   \n",
       "4   https://twitter.com/kennethdashen  11-03-20 00:45   \n",
       "\n",
       "                                       Tweet_Content Tweet_Number_of_Likes  \\\n",
       "0  @CWAUnion\\n Is the union able to take measures...                     0   \n",
       "1  I’m looking forward to working from home a lot...                     0   \n",
       "2  China team work from home more than 1 month al...                     0   \n",
       "3  We are about to find out how much work could h...                   363   \n",
       "4  Folks who can't #WorkFromHome probably hate th...                     1   \n",
       "\n",
       "  Tweet_Number_of_Retweets  Tweet_Number_of_Reviews  \n",
       "0                        0                      0.0  \n",
       "1                        0                      0.0  \n",
       "2                        0                      0.0  \n",
       "3                       28                     14.0  \n",
       "4                        0                      0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace NaN values with zeros for Tweet Number of Likes, Retweets and Reviews\n",
    "raw_dataset[[\"Tweet_Number_of_Likes\",\"Tweet_Number_of_Retweets\", \"Tweet_Number_of_Reviews\"]] = raw_dataset[[\"Tweet_Number_of_Likes\",\"Tweet_Number_of_Retweets\", \"Tweet_Number_of_Reviews\"]].fillna(0)\n",
    "raw_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Keyword                      object\n",
       "Web_Page_URL                 object\n",
       "Tweet_Website                object\n",
       "Author_Name                  object\n",
       "Author_Web_Page_URL          object\n",
       "Tweet_Time                   object\n",
       "Tweet_Content                object\n",
       "Tweet_Number_of_Likes        object\n",
       "Tweet_Number_of_Retweets     object\n",
       "Tweet_Number_of_Reviews     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the datatypes of the columns\n",
    "raw_dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the datatype of the columns that contain numeric values from object to Int64 type\n",
    "raw_dataset['Tweet_Number_of_Likes'] = pd.to_numeric(raw_dataset['Tweet_Number_of_Likes'], errors='coerce').astype('Int64')\n",
    "raw_dataset['Tweet_Number_of_Retweets'] = pd.to_numeric(raw_dataset['Tweet_Number_of_Retweets'], errors='coerce').astype('Int64')\n",
    "raw_dataset['Tweet_Number_of_Reviews'] = pd.to_numeric(raw_dataset['Tweet_Number_of_Reviews'], errors='coerce').astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Todo: Convert Tweet_Time from object type to data type"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to preprocess the Tweets for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_stop_words(path_to_stopwords):\n",
    "    \"\"\"Function to read a .txt file containing (custom) stop words and return a set of these stop words.\n",
    "    Args:\n",
    "        path_to_stopwords (str): path to the.txt file containing stop words (e.g. /your/path/to/files/stop_words.txt)\n",
    "    Returns:\n",
    "        set: set of stop words\n",
    "    \"\"\"    \n",
    "    stop_words = set()\n",
    "    with open(path_to_stopwords, 'r') as f:\n",
    "        for line in f:\n",
    "            word = line.strip()  # remove whitespace and newline characters\n",
    "            stop_words.add(word)\n",
    "    return stop_words\n",
    "\n",
    "\n",
    "def remove_emoji(text):\n",
    "    \"\"\"Function that takes a text string as input and uses a regular expression pattern to match all Unicode characters\n",
    "    that are classified as emojis. The regular expression includes different ranges of Unicode characters \n",
    "    that represent different types of emojis, such as emoticons, symbols, and flags.\n",
    "    Args:\n",
    "        text (str): text string to remove emojis from\n",
    "    Returns:\n",
    "        str: text string with all emojis removed\n",
    "    \"\"\"    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "def remove_stopwords(text, stop_words):\n",
    "    \"\"\"Function that removes stop words from a given text.\n",
    "    Args:\n",
    "        text (str): text string\n",
    "        stop_words (set): set of stop words\n",
    "    Returns:\n",
    "        str: text string without stop words\n",
    "    \"\"\"    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove the stopwords\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "\n",
    "    # Join the filtered tokens back into a string\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "\n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "def clean_text(text, stop_words):\n",
    "    \"\"\"Function to clean the raw text, e.g. from a tweet. Performs the following steps:\n",
    "    1. Lowercase all the words in the text\n",
    "    2. Replace all new line characters with a white space\n",
    "    3. Remove tags\n",
    "    4. Remove URLs\n",
    "    5. Convert contractions to their full forms\n",
    "    6. Remove punctuations\n",
    "    7. Remove emojis (emoticons, symbols, flags, etc.)\n",
    "    8. Remove stopwords\n",
    "    Args:\n",
    "        text (str): text string to be cleaned before passing it to the sentiment analysis model\n",
    "        stop_words (set): set of stop words to be removed from the text\n",
    "    Returns:\n",
    "        str: cleaned text string\n",
    "    \"\"\"        \n",
    "    # 1. Lowercase all words in the text\n",
    "    text = text.lower()\n",
    "\n",
    "    # 2. Replace the new line character with empty string\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    \n",
    "    # 3. Remove words starting with '@' - tags (most common noise in replies)\n",
    "    text = re.sub(r'@\\w+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # 4. Remove words starting with 'http' - hyperlinks\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # 5. Remove contractions, such as you're => you are\n",
    "    contractions.fix(text)\n",
    "\n",
    "    # 6. Remove punctuation from the text using regular expressions\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # 7. Remove emojis\n",
    "    text = remove_emoji(text)\n",
    "\n",
    "    # 8. Remove stopwords in English\n",
    "    text = remove_stopwords(text, stop_words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Populating the set of stop words from the text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the path to the root directory of the filesystem\n",
    "root_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'an',\n",
       " 'and',\n",
       " 'at',\n",
       " 'been',\n",
       " 'being',\n",
       " 'had',\n",
       " 'it',\n",
       " 'its',\n",
       " 'o',\n",
       " 'of',\n",
       " 'or',\n",
       " 'so',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'this',\n",
       " 'to',\n",
       " 'which',\n",
       " 'y'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = custom_stop_words(os.path.join(root_dir,'stopwords.txt'))\n",
    "stopwords"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for SentiStrength library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_sentistrength = os.path.join(root_dir, 'SentiStrength')\n",
    "# Replace with the path to the Java executable file of SentiStrength.\n",
    "path_to_sentistrength_jar = os.path.join(path_to_sentistrength, 'SentiStrengthCom.jar')\n",
    "# Replace with the path to the language folder, which is used along with the .jar file to compute sentiment scores.\n",
    "path_to_sentistrength_language_folder = os.path.join(path_to_sentistrength, 'LanguageFolder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti = PySentiStr()\n",
    "senti.setSentiStrengthPath(path_to_sentistrength_jar)\n",
    "senti.setSentiStrengthLanguageFolderPath(path_to_sentistrength_language_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_Time</th>\n",
       "      <th>Tweet_Content</th>\n",
       "      <th>Cleaned_Tweet</th>\n",
       "      <th>Sentiment_Score</th>\n",
       "      <th>Binary_Score</th>\n",
       "      <th>Tweet_Number_of_Likes</th>\n",
       "      <th>Tweet_Number_of_Retweets</th>\n",
       "      <th>Tweet_Number_of_Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11-03-20 00:14</td>\n",
       "      <td>@CWAUnion\\n Is the union able to take measures...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11-03-20 00:23</td>\n",
       "      <td>I’m looking forward to working from home a lot...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-03-20 00:23</td>\n",
       "      <td>China team work from home more than 1 month al...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11-03-20 00:39</td>\n",
       "      <td>We are about to find out how much work could h...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>363</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11-03-20 00:45</td>\n",
       "      <td>Folks who can't #WorkFromHome probably hate th...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tweet_Time                                      Tweet_Content  \\\n",
       "0  11-03-20 00:14  @CWAUnion\\n Is the union able to take measures...   \n",
       "1  11-03-20 00:23  I’m looking forward to working from home a lot...   \n",
       "2  11-03-20 00:23  China team work from home more than 1 month al...   \n",
       "3  11-03-20 00:39  We are about to find out how much work could h...   \n",
       "4  11-03-20 00:45  Folks who can't #WorkFromHome probably hate th...   \n",
       "\n",
       "  Cleaned_Tweet  Sentiment_Score  Binary_Score  Tweet_Number_of_Likes  \\\n",
       "0                              0             0                      0   \n",
       "1                              0             0                      0   \n",
       "2                              0             0                      0   \n",
       "3                              0             0                    363   \n",
       "4                              0             0                      1   \n",
       "\n",
       "   Tweet_Number_of_Retweets  Tweet_Number_of_Reviews  \n",
       "0                         0                        0  \n",
       "1                         0                        0  \n",
       "2                         0                        0  \n",
       "3                        28                       14  \n",
       "4                         0                        0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new dataframe with the desired columns for sentiment analysis, initializing empty columns for Cleaned_Tweet, Sentiment_Score, and Dual_Score\n",
    "new_dataset = pd.DataFrame({\n",
    "    'Tweet_Time': raw_dataset['Tweet_Time'],\n",
    "    'Tweet_Content': raw_dataset['Tweet_Content'],\n",
    "    'Cleaned_Tweet': [''] * len(raw_dataset), # initializing empty values for Cleaned_Tweet\n",
    "    'Sentiment_Score': [0] * len(raw_dataset), # initializing empty values for Sentiment_Score\n",
    "    'Binary_Score': [0] * len(raw_dataset), # initializing empty values for Binary_Score\n",
    "    'Tweet_Number_of_Likes': raw_dataset['Tweet_Number_of_Likes'],\n",
    "    'Tweet_Number_of_Retweets': raw_dataset['Tweet_Number_of_Retweets'],\n",
    "    'Tweet_Number_of_Reviews': raw_dataset['Tweet_Number_of_Reviews']\n",
    "})\n",
    "new_dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_Time</th>\n",
       "      <th>Tweet_Content</th>\n",
       "      <th>Cleaned_Tweet</th>\n",
       "      <th>Sentiment_Score</th>\n",
       "      <th>Binary_Score</th>\n",
       "      <th>Tweet_Number_of_Likes</th>\n",
       "      <th>Tweet_Number_of_Retweets</th>\n",
       "      <th>Tweet_Number_of_Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11-03-20 00:14</td>\n",
       "      <td>@CWAUnion\\n Is the union able to take measures...</td>\n",
       "      <td>is union able take measures in getting deal wi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11-03-20 00:23</td>\n",
       "      <td>I’m looking forward to working from home a lot...</td>\n",
       "      <td>im looking forward working from home a lot bec...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-03-20 00:23</td>\n",
       "      <td>China team work from home more than 1 month al...</td>\n",
       "      <td>china team work from home more than 1 month al...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11-03-20 00:39</td>\n",
       "      <td>We are about to find out how much work could h...</td>\n",
       "      <td>we are about find out how much work could have...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>363</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11-03-20 00:45</td>\n",
       "      <td>Folks who can't #WorkFromHome probably hate th...</td>\n",
       "      <td>folks who cant workfromhome probably hate i fe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tweet_Time                                      Tweet_Content  \\\n",
       "0  11-03-20 00:14  @CWAUnion\\n Is the union able to take measures...   \n",
       "1  11-03-20 00:23  I’m looking forward to working from home a lot...   \n",
       "2  11-03-20 00:23  China team work from home more than 1 month al...   \n",
       "3  11-03-20 00:39  We are about to find out how much work could h...   \n",
       "4  11-03-20 00:45  Folks who can't #WorkFromHome probably hate th...   \n",
       "\n",
       "                                       Cleaned_Tweet  Sentiment_Score  \\\n",
       "0  is union able take measures in getting deal wi...                0   \n",
       "1  im looking forward working from home a lot bec...                0   \n",
       "2  china team work from home more than 1 month al...                0   \n",
       "3  we are about find out how much work could have...                0   \n",
       "4  folks who cant workfromhome probably hate i fe...                0   \n",
       "\n",
       "   Binary_Score  Tweet_Number_of_Likes  Tweet_Number_of_Retweets  \\\n",
       "0             0                      0                         0   \n",
       "1             0                      0                         0   \n",
       "2             0                      0                         0   \n",
       "3             0                    363                        28   \n",
       "4             0                      1                         0   \n",
       "\n",
       "   Tweet_Number_of_Reviews  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                       14  \n",
       "4                        0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset['Cleaned_Tweet'] = new_dataset['Tweet_Content'].apply(lambda x: clean_text(x, stopwords))\n",
    "new_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mint\u001b[39m(result[\u001b[39m0\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[39m# apply the compute_sentiment_score function to each row of the 'Cleaned_Tweet' column and store the results in the 'Sentiment_Score' column\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m new_dataset[\u001b[39m'\u001b[39m\u001b[39mSentiment_Score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m new_dataset[\u001b[39m'\u001b[39m\u001b[39mCleaned_Tweet\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(compute_sentiment_score)\n",
      "File \u001b[1;32mc:\\Users\\crist\\anaconda3\\envs\\Dissertation\\Lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39mapply()\n",
      "File \u001b[1;32mc:\\Users\\crist\\anaconda3\\envs\\Dissertation\\Lib\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\crist\\anaconda3\\envs\\Dissertation\\Lib\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mmap_infer(\n\u001b[0;32m   1175\u001b[0m             values,\n\u001b[0;32m   1176\u001b[0m             f,\n\u001b[0;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_dtype,\n\u001b[0;32m   1178\u001b[0m         )\n\u001b[0;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\crist\\anaconda3\\envs\\Dissertation\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[67], line 3\u001b[0m, in \u001b[0;36mcompute_sentiment_score\u001b[1;34m(tweet_text)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_sentiment_score\u001b[39m(tweet_text):\n\u001b[1;32m----> 3\u001b[0m     result \u001b[39m=\u001b[39m senti\u001b[39m.\u001b[39mgetSentiment(tweet_text)\n\u001b[0;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mint\u001b[39m(result[\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\crist\\anaconda3\\envs\\Dissertation\\Lib\\site-packages\\sentistrength\\__init__.py:35\u001b[0m, in \u001b[0;36mPySentiStr.getSentiment\u001b[1;34m(self, df_text, score)\u001b[0m\n\u001b[0;32m     33\u001b[0m p \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39mPopen(shlex\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39mjava -jar \u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mSentiStrengthLocation \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m stdin sentidata \u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mSentiStrengthLanguageFolder \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m trinary\u001b[39m\u001b[39m\"\u001b[39m),stdin\u001b[39m=\u001b[39msubprocess\u001b[39m.\u001b[39mPIPE,stdout\u001b[39m=\u001b[39msubprocess\u001b[39m.\u001b[39mPIPE,stderr\u001b[39m=\u001b[39msubprocess\u001b[39m.\u001b[39mPIPE)\n\u001b[0;32m     34\u001b[0m b \u001b[39m=\u001b[39m \u001b[39mbytes\u001b[39m(conc_text\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m), \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m stdout_byte, stderr_text \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39mcommunicate(b)\n\u001b[0;32m     36\u001b[0m stdout_text \u001b[39m=\u001b[39m stdout_byte\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m stdout_text \u001b[39m=\u001b[39m stdout_text\u001b[39m.\u001b[39mrstrip()\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\crist\\anaconda3\\envs\\Dissertation\\Lib\\subprocess.py:1207\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m   1204\u001b[0m     endtime \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1206\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1207\u001b[0m     stdout, stderr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_communicate(\u001b[39minput\u001b[39m, endtime, timeout)\n\u001b[0;32m   1208\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1209\u001b[0m     \u001b[39m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[0;32m   1210\u001b[0m     \u001b[39m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\crist\\anaconda3\\envs\\Dissertation\\Lib\\subprocess.py:1597\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[1;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[0;32m   1593\u001b[0m \u001b[39m# Wait for the reader threads, or time out.  If we time out, the\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m \u001b[39m# threads remain reading and the fds left open in case the user\u001b[39;00m\n\u001b[0;32m   1595\u001b[0m \u001b[39m# calls communicate again.\u001b[39;00m\n\u001b[0;32m   1596\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout_thread\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_remaining_time(endtime))\n\u001b[0;32m   1598\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout_thread\u001b[39m.\u001b[39mis_alive():\n\u001b[0;32m   1599\u001b[0m         \u001b[39mraise\u001b[39;00m TimeoutExpired(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, orig_timeout)\n",
      "File \u001b[1;32mc:\\Users\\crist\\anaconda3\\envs\\Dissertation\\Lib\\threading.py:1112\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1109\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1111\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1112\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock()\n\u001b[0;32m   1113\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1114\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1116\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\crist\\anaconda3\\envs\\Dissertation\\Lib\\threading.py:1132\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39macquire(block, timeout):\n\u001b[0;32m   1133\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m   1134\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define a function to compute the sentiment score for a given tweet text\n",
    "def compute_sentiment_score(tweet_text):\n",
    "    result = senti.getSentiment(tweet_text)\n",
    "    return int(result[0])\n",
    "\n",
    "# apply the compute_sentiment_score function to each row of the 'Cleaned_Tweet' column and store the results in the 'Sentiment_Score' column\n",
    "new_dataset['Sentiment_Score'] = new_dataset['Cleaned_Tweet'].apply(compute_sentiment_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scor = new_dataset.loc[3,'Cleaned_Tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'we are about find out how much work could have actually done better home in sweats on couch petting your doga lot answer is going be a lot covid19 coronavirus covid2019 workfromhome'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How many of you are working from home due to #coronavirus ?\\n\\nOur HR sent us an email today asking to stay home. What a blessing to work for a company who cares so much about their people  #blessed \\n\\n#WorkFromHome'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset.loc[81, 'Tweet_Content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how many you are working home due coronavirus hr sent us email today asking stay home what blessing work company who cares much people blessed workfromhome'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned = clean_text(raw_dataset.loc[81, 'Tweet_Content'], stopwords)\n",
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scor = senti.getSentiment(cleaned, score='binary')\n",
    "scor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dissertation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f4cb87ef8bed4e72b4244962ebc25b4a166307cb6901c81260d8950270ff9490"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
